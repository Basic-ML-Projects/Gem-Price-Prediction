# Gem-Price-Prediction
A through hands-on work through of Kaggle's Gem Price Prediction dataset. The point of this project was to introduce different methods to achieve a better accuracy for our regression models. However, we find that time and memory becomes a problem as a result of these advanced techniques. In the prediction.ipynb, I walk through different implementations that could be made in the preprocessing and model building steps and show how time becomes a factor. Although I did not explicity show the memory usage, anyone willing to try these techniques for themselves will see it first hand. For me, implementing a stack of 10 models and training it overloaded the cpu ram provided by colab. I might show the usage of some of the functions I made and their results in the future, but for now, I leave it up to anyone who sees this project to implement themselves so they can see what happens first-hand. After all, the best way to learn is by doing.

Dataset: https://www.kaggle.com/competitions/playground-series-s3e8/data


